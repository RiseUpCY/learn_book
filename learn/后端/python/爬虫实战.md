# 爬虫实践

[入门博客](https://cuijiahua.com/blog/spider/)

[w3c](https://www.w3cschool.cn/python3/)

## 基本描述

[requests 中文 Doc](https://cn.python-requests.org/zh_CN/latest/)

[Beautiful Soup 中文 Doc](https://beautifulsoup.readthedocs.io/zh_CN/latest/)

[教程博文](https://blog.csdn.net/c406495762/article/details/78123502)

```python
# 使用 requests 库 或者 urllib 库 抓取网页数据
pip install requests

# 使用 Beautiful Soup 解析 html 文本
pip install beautifulsoup4
或
easy_install beautifulsoup4


```

## 常见问题

### 编码问题

```python
req = requests.get(url=url)
req.encoding            # 当前编码
req.apparent_encoding   # 页面的真实编码
req.encoding = 'GB2312' # 设为页面的真实编码，apparent_encoding
```

### session

```python
# 使用 requests 提供的会话管理
s = requests.session()
s.get()

```

### 文件存储

[pillow 常用方法](https://www.cnblogs.com/chimeiwangliang/p/7130434.html)

```python
req = requests.get(url=img_src, headers=headers, verify=False)
# 二进制
f = open('./a.jpg', 'ab') # 追加写入二进制， 不仅仅是图片
f.write(req.content)
f.close()

# urllib 库中下载文件的方法
from urllib.request import urlretrieve
urlretrieve(IMAGE_URL, './image/img1.png')

# 图片的其他方式
from PIL import Image
from io import BytesIO
i = Image.open(BytesIO(r.content))

```

### https 不友好

```python
# requests 库对 https 不友好，就用原生的解决， 或者使用 selenuim
url = 'https://qqchub.com/index.php/ajax/data.html?mid=1&page=1&limit=8&tid=all&by=t&level=1'

headers = {
    'Content-Type': 'application/json',
    "User-Agent": "Mozilla/5.0 (Linux; Android 8.0.0; MIX 2S Build/OPR1.170623.032)\
    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.84 Mobile Safari/537.36",
}

req = urllib.request.Request(url=url, headers=headers)

res = urllib.request.urlopen(req)

data = res.read().decode('utf-8')

data = json.loads(data)

f = open('list.txt', 'wb')

pickle.dump(data, f)
f.close()
```
